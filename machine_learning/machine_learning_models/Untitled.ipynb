{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set(rc={'figure.figsize':(14,8)}, font_scale=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned-Data-covid.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = ['Fever', 'Tiredness', 'Dry-Cough',  'Difficulty-in-Breathing', 'Sore-Throat', 'Pains', 'Nasal-Congestion',\n",
    "              'Runny-Nose', 'Diarrhea', 'Age_0-9', 'Age_10-19', 'Age_20-24', 'Age_25-59', 'Age_60+', 'Gender_Male',\n",
    "              'Gender_Female', 'Gender_Transgender']\n",
    "target_columns = ['Severity_None']\n",
    "indicators2 = ['Fever', 'Tiredness', 'Dry-Cough',  'Difficulty-in-Breathing', 'Sore-Throat', 'Pains', 'Nasal-Congestion',\n",
    "              'Runny-Nose', 'Diarrhea', 'Age_0-9', 'Age_10-19', 'Age_20-24', 'Age_25-59', 'Age_60+', 'Gender_Male',\n",
    "              'Gender_Female', 'Gender_Transgender', 'Severity_None']\n",
    "features = df[indicators]\n",
    "targets = df[target_columns]\n",
    "display(features.head(), targets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition = []\n",
    "# cond_dict = {\n",
    "#     0: \"Mild\",\n",
    "#     1: \"Moderate\",\n",
    "#     2: \"Severe\"\n",
    "# }\n",
    "# for i in targets.values:\n",
    "#     idx = np.where(i == 1)[0][0]\n",
    "#     condition.append(cond_dict[idx])\n",
    "# targets['Condition'] = condition\n",
    "sns.set(rc={'figure.figsize':(12,8)}, font_scale=.9)\n",
    "targets = targets.rename(columns={'Severity_None':'Non_Severe'})\n",
    "sns.countplot(targets['Non_Severe'])\n",
    "plt.title(\"Severity Data Distribution\")\n",
    "plt.show()\n",
    "sns.set(rc={'figure.figsize':(12,8)}, font_scale=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in indicators:\n",
    "    temp.append(sum(features[i].values))\n",
    "temp_df = pd.DataFrame({\"Indicator\":indicators, \"Occurence_Count\":temp})\n",
    "sns.barplot(data = temp_df, y=\"Indicator\", x=\"Occurence_Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(data=temp_df, x=\"Occurence_Count\", labels=temp_df[\"Indicator\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symptom_count(the_list):\n",
    "    return sum(the_list.values)\n",
    "features['Total_Symptom'] = features[indicators].apply(get_symptom_count, axis=1)\n",
    "feats = df[indicators2]\n",
    "feats['Total_Symptom'] = feats[indicators].apply(get_symptom_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=feats, x='Total_Symptom', hue='Severity_None')\n",
    "plt.xlabel(\"Total symptom occurence on someone\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features\n",
    "data['Non_Severe'] = targets['Non_Severe'].values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_corr = data.drop(labels=\"Total_Symptom\", axis=1)\n",
    "# data_for_corr['Condition'] = data_for_corr['Condition'].apply(make_condition_grade)\n",
    "corrmat = data_for_corr.corr()\n",
    "k = 22\n",
    "cols = corrmat.nlargest(k, 'Non_Severe')['Non_Severe'].index\n",
    "cm = np.corrcoef(data_for_corr[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['Non_Severe', 'Total_Symptom'], axis=1)\n",
    "x = PCA(n_components = 3).fit_transform(x)\n",
    "y = data['Non_Severe']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(x_train, y_train)\n",
    "DTC.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\":[15,20,25], \n",
    "    \"n_estimators\":[27,30,33],\n",
    "    \"criterion\":[\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rf_reg = GridSearchCV(rfc, params, cv = 10, n_jobs =10)\n",
    "rf_reg.fit(x_train, y_train)\n",
    "print(rf_reg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tune = RandomForestClassifier(max_depth=15, n_estimators=27)\n",
    "rfc_tune.fit(x_train, y_train)\n",
    "score = cross_val_score(rfc,x_test,y_test,cv = k_fold,n_jobs=1,scoring=\"accuracy\")\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"penalty\":['l1', 'l2', 'elasticnet', 'none'],\n",
    "    \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "lr_reg = GridSearchCV(lr, params, cv=10, n_jobs=10)\n",
    "lr_reg.fit(x_train, y_train)\n",
    "print(lr_reg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lr_tune.fit(x_train, y_train)\n",
    "score = cross_val_score(lr_tune, x_test, y_test, cv=k_fold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"criterion\":[\"gini\", \"entropy\"],\n",
    "    \"max_depth\":[15,20,25], \n",
    "}\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_reg = GridSearchCV(dtc, params, cv=10, n_jobs=10)\n",
    "dtc_reg.fit(x_train, y_train)\n",
    "print(dtc_reg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_tune = DecisionTreeClassifier(max_depth=15)\n",
    "dtc_tune.fit(x_train, y_train)\n",
    "score = cross_val_score(dtc_tune, x_test, y_test, cv=k_fold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
